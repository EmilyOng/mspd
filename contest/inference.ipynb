{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputDf = pd.read_csv(\"testcases/input_stt_45.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>netIdx</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>x40</th>\n",
       "      <th>y40</th>\n",
       "      <th>x41</th>\n",
       "      <th>y41</th>\n",
       "      <th>x42</th>\n",
       "      <th>y42</th>\n",
       "      <th>x43</th>\n",
       "      <th>y43</th>\n",
       "      <th>x44</th>\n",
       "      <th>y44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>810</td>\n",
       "      <td>676</td>\n",
       "      <td>311</td>\n",
       "      <td>352</td>\n",
       "      <td>937</td>\n",
       "      <td>197</td>\n",
       "      <td>748</td>\n",
       "      <td>790</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>365</td>\n",
       "      <td>999</td>\n",
       "      <td>156</td>\n",
       "      <td>372</td>\n",
       "      <td>248</td>\n",
       "      <td>537</td>\n",
       "      <td>555</td>\n",
       "      <td>218</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     netIdx   x0   y0   x1   y1   x2   y2   x3   y3  x4  ...  x40  y40  x41  \\\n",
       "299     299  810  676  311  352  937  197  748  790  43  ...   45  365  999   \n",
       "\n",
       "     y41  x42  y42  x43  y43  x44  y44  \n",
       "299  156  372  248  537  555  218  263  \n",
       "\n",
       "[1 rows x 91 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDf[inputDf[\"netIdx\"] == 299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbours(points):\n",
    "    N = len(points)\n",
    "    \n",
    "    upper_right = [float(\"inf\") for i in range(N)]\n",
    "    upper_left = [float(\"-inf\") for i in range(N)]\n",
    "    lower_right = [float(\"inf\") for i in range(N)]\n",
    "    lower_left = [float(\"-inf\") for i in range(N)]\n",
    "    \n",
    "    nearest_neighbours = [[] for i in range(N)]\n",
    "    \n",
    "    # Sort the points by y-coordinates (point_index = ((x, y), i))\n",
    "    sorted_points = sorted(points, key=lambda point_index: point_index[0][1])\n",
    "    \n",
    "    for i in range(N):\n",
    "        a_index = sorted_points[i][1]\n",
    "        a_x = sorted_points[i][0][0]\n",
    "        \n",
    "        for j in range(i):\n",
    "            b_index = sorted_points[j][1]\n",
    "            b_x = sorted_points[j][0][0]\n",
    "            \n",
    "            if b_x <= a_x and a_x < upper_right[b_index]:\n",
    "                upper_right[b_index] = a_x\n",
    "                nearest_neighbours[b_index].append(a_index)\n",
    "            elif upper_left[b_index] < a_x and a_x < b_x:\n",
    "                upper_left[b_index] = a_x\n",
    "                nearest_neighbours[b_index].append(a_index)\n",
    "                \n",
    "        for j in range(i - 1, -1, -1):\n",
    "            b_index = sorted_points[j][1]\n",
    "            b_x = sorted_points[j][0][0]\n",
    "            if a_x <= b_x and b_x < lower_right[a_index]:\n",
    "                lower_right[a_index] = b_x\n",
    "                nearest_neighbours[a_index].append(b_index)\n",
    "            elif lower_left[a_index] < b_x and b_x < a_x:\n",
    "                lower_left[a_index] = b_x\n",
    "                nearest_neighbours[a_index].append(b_index)\n",
    "    \n",
    "    return nearest_neighbours\n",
    "    \n",
    "    \n",
    "def dfs(at, dist, adj_list, points, subtree, count, parent_count, pathlengths):\n",
    "    subtree[at].add(at)\n",
    "    pathlengths[at] = dist\n",
    "    parent_count[at] += 1\n",
    "    count[at] += 1\n",
    "\n",
    "    for node in adj_list[at]:\n",
    "        if node == at:\n",
    "            continue\n",
    "        dfs(node, dist + manhattan_distance(\n",
    "            points[at][0][0], points[at][0][1],\n",
    "            points[node][0][0], points[node][0][1]\n",
    "        ), adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "        for v in subtree[node]:\n",
    "            subtree[at].add(v)\n",
    "        count[at] += count[node]\n",
    "    \n",
    "\n",
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "\n",
    "\n",
    "def calc_wl(adj_list, points):\n",
    "    total = 0\n",
    "    for i in range(len(points)):\n",
    "        for node in adj_list[i]:\n",
    "            total += manhattan_distance(\n",
    "                points[i][0][0], points[i][0][1],\n",
    "                points[node][0][0], points[node][0][1]\n",
    "            )\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "def calc_skew(adj_list, points, N):\n",
    "    parent_count = [0 for i in range(len(points))]\n",
    "    count = [0 for i in range(len(points))]\n",
    "    pathlengths = [0 for i in range(len(points))]\n",
    "    \n",
    "    subtree = [set() for i in range(len(points))]\n",
    "    \n",
    "    dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "    \n",
    "    mx = 0\n",
    "    mn = 1000000000\n",
    "    \n",
    "    for i in range(1, N):\n",
    "        mx = max(mx, pathlengths[i])\n",
    "        mn = min(mn, pathlengths[i])\n",
    "        \n",
    "    return mx - mn\n",
    "\n",
    "\n",
    "def steinerize(points, adj_list, parents):\n",
    "    N = len(points)\n",
    "    \n",
    "    def best_steiner_node(index):\n",
    "        a, b = 0, 0\n",
    "        best = 0\n",
    "        b_x, b_y = 0, 0\n",
    "        \n",
    "        for node_a in adj_list[index]:\n",
    "            if node_a == index:\n",
    "                continue\n",
    "                \n",
    "            for node_b in adj_list[index]:\n",
    "                if node_b == index or node_a == node_b:\n",
    "                    continue\n",
    "                    \n",
    "            s_x = points[index][0]\n",
    "            s_y = points[index][1]\n",
    "            \n",
    "            if min(points[node_a][0], points[node_b][0]) > points[index][0]:\n",
    "                s_x = min(points[node_a][0], points[node_b][0])\n",
    "            elif max(points[node_a][0], points[node_b][0]) < points[index][0]:\n",
    "                s_x = max(points[node_a][0], points[node_b][0])\n",
    "            \n",
    "            if min(points[node_a][1], points[node_b][1]) > points[index][1]:\n",
    "                s_y = min(points[node_a][1], points[node_b][1])\n",
    "            elif max(points[node_a][1], points[node_b][1]) < points[index][1]:\n",
    "                s_y = max(points[node_a][1], points[node_b][1])\n",
    "                \n",
    "            gain = abs(points[index][0] - s_x) + abs(points[index][1] - s_y)\n",
    "            if gain > best:\n",
    "                best = gain\n",
    "                a, b = node_a, node_b\n",
    "                b_x, b_y = s_x, s_y\n",
    "                \n",
    "        return (-best, index, a, b, b_x, b_y)\n",
    "    \n",
    "    \n",
    "    pq = set()\n",
    "    steiner_nodes = [[] for i in range(len(points))]\n",
    "    for i in range(1, len(points)):\n",
    "        new_node = best_steiner_node(i)\n",
    "        pq.add(new_node)\n",
    "        steiner_nodes[i] = new_node\n",
    "        \n",
    "    while len(pq) > 0:\n",
    "        curr_node = next(iter(pq))\n",
    "        pq.remove(curr_node)\n",
    "        \n",
    "        if curr_node[0] == 0:\n",
    "            break\n",
    "            \n",
    "        a, b = curr_node[2], curr_node[3]\n",
    "        steiner_node = N\n",
    "        \n",
    "        if points[a][0] == curr_node[4] and points[a][1] == curr_node[5]:\n",
    "            steiner_node = a\n",
    "        elif points[b][0] == curr_node[4] and points[b][1] == curr_node[5]:\n",
    "            steiner_node = b\n",
    "        else:\n",
    "            points.append(((curr_node[4], curr_node[5]), steiner_node))\n",
    "            points[steiner_node][0] = curr_node[4]\n",
    "            points[steiner_node][1] = curr_node[5]\n",
    "            \n",
    "        if a != steiner_node:\n",
    "            adj_list[curr_node[1]].remove(a)\n",
    "            adj_list[curr_node[1]].add(steiner_node)\n",
    "            parents[steiner_node] = curr_node[1]\n",
    "            adj_list[steiner_node].add(a)\n",
    "            parents[a] = steiner_node\n",
    "            parents[steiner_node] = curr_node[1]\n",
    "        if b != steiner_node:\n",
    "            adj_list[curr_node[1]].remove(b)\n",
    "            adj_list[curr_node[1]].add(steiner_node)\n",
    "            parents[steiner_node] = curr_node[1]\n",
    "            adj_list[steiner_node].add(b)\n",
    "            parents[b] = steiner_node\n",
    "            parents[steiner_node] = curr_node[1]\n",
    "            \n",
    "        steiner_nodes[curr_node[1]] = best_steiner_node(curr_node[1])\n",
    "        pq.add(steiner_nodes[curr_node[1]])\n",
    "        \n",
    "        pq.discard(steiner_nodes[a])\n",
    "        pq.discard(steiner_nodes[b])\n",
    "        \n",
    "        steiner_nodes[a] = best_steiner_node(a)\n",
    "        pq.add(steiner_nodes[a])\n",
    "        \n",
    "        steiner_nodes[b] = best_steiner_node(b)\n",
    "        pq.add(steiner_nodes[b])\n",
    "\n",
    "\n",
    "\n",
    "def das(source_set, adj_list, parents, N, points): # Detour-Aware Steinerization\n",
    "    nearest_neighbours = get_nearest_neighbours(points)\n",
    "    \n",
    "    subtree = [set() for i in range(len(points))]\n",
    "    \n",
    "    parent_count = [0 for i in range(len(points))]\n",
    "    count = [0 for i in range(len(points))]\n",
    "    pathlengths = [0 for i in range(len(points))]\n",
    "    \n",
    "    DT = [0 for i in range(len(points))]\n",
    "    \n",
    "    def get_dt(at, parent):\n",
    "        DT[at] = pathlengths[at] - manhattan_distance(\n",
    "            points[at][0][0], points[at][0][1],\n",
    "            0, 0\n",
    "        )\n",
    "        for node in adj_list[at]:\n",
    "            if node == at:\n",
    "                continue\n",
    "            get_dt(node, at)\n",
    "\n",
    "    \n",
    "    dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "    \n",
    "    max_pathlength = 0\n",
    "    for i in range(N):\n",
    "        max_pathlength = max(max_pathlength, pathlengths[i])\n",
    "        \n",
    "    for i in range(1, len(points)):\n",
    "        if i in source_set:\n",
    "            continue\n",
    "            \n",
    "        edge_length = manhattan_distance(\n",
    "            points[parents[i]][0][0], points[parents[i]][0][1],\n",
    "            points[i][0][0], points[i][0][1]\n",
    "        )\n",
    "\n",
    "        best_nn = parents[i]\n",
    "\n",
    "        if best_nn >= N:\n",
    "            continue\n",
    "\n",
    "        for node in nearest_neighbours[i]:\n",
    "            if node == 0:\n",
    "                continue\n",
    "                \n",
    "            distance = manhattan_distance(\n",
    "                points[node][0][0], points[node][0][1],\n",
    "                points[i][0][0], points[i][0][1]\n",
    "            )\n",
    "            if distance <= edge_length and pathlengths[i] <= 0.5 * max_pathlength:\n",
    "                if node not in subtree[i]:\n",
    "                    best_nn = node\n",
    "                    edge_length = distance\n",
    "                \n",
    "        adj_list[parents[i]].remove(i)\n",
    "        parents[i] = best_nn\n",
    "        adj_list[parents[i]].add(i)\n",
    "        \n",
    "        for j in range(len(points)):\n",
    "            subtree[j].clear()\n",
    "            pathlengths[j] = 0\n",
    "            parent_count[j] = 0\n",
    "            count[j] = 0\n",
    "        \n",
    "        dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "    \n",
    "    for i in range(len(points)):\n",
    "        subtree[i].clear()\n",
    "        parent_count[i] = 0\n",
    "        count[i] = 0\n",
    "        pathlengths[i] = 0\n",
    "        \n",
    "    dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "    get_dt(0, 0)\n",
    "    \n",
    "    max_pathlength = 0\n",
    "    curr_dt = 0\n",
    "    curr_wl = calc_wl(adj_list, points)\n",
    "    \n",
    "    for i in range(N):\n",
    "        max_pathlength = max(max_pathlength, pathlengths[i])\n",
    "    for i in range(len(points)):\n",
    "        curr_dt += DT[i]\n",
    "        \n",
    "    for i in range(1, len(points)):\n",
    "        if i in source_set:\n",
    "            continue\n",
    "            \n",
    "        new_parent = parents[i]\n",
    "        if new_parent >= N:\n",
    "            continue\n",
    "        \n",
    "        for node in nearest_neighbours[i]:\n",
    "            if node == 0:\n",
    "                continue\n",
    "            \n",
    "            new_wl = curr_wl - manhattan_distance(\n",
    "                points[i][0][0], points[i][0][1],\n",
    "                points[parents[i]][0][0], points[parents[i]][0][1]\n",
    "            ) + manhattan_distance(\n",
    "                points[i][0][0], points[i][0][1],\n",
    "                points[node][0][0], points[node][0][1]\n",
    "            )\n",
    "            new_dt = curr_dt - manhattan_distance(\n",
    "                points[i][0][0], points[i][0][1],\n",
    "                points[parents[i]][0][0], points[parents[i]][0][1]\n",
    "            ) * count[i] - manhattan_distance(\n",
    "                points[i][0][0], points[i][0][1],\n",
    "                points[node][0][0], points[node][0][1]\n",
    "            ) * count[i]\n",
    "            \n",
    "            if new_wl <= curr_wl and new_dt <= curr_dt:\n",
    "                if node not in subtree[i]:\n",
    "                    curr_wl = new_wl\n",
    "                    curr_dt = new_dt\n",
    "                    new_parent = node\n",
    "                    \n",
    "        adj_list[parents[i]].remove(i)\n",
    "        parents[i] = new_parent\n",
    "        adj_list[parents[i]].add(i)\n",
    "        \n",
    "        for j in range(len(points)):\n",
    "            subtree[j].clear()\n",
    "            parent_count[j] = 0\n",
    "            count[j] = 0\n",
    "            pathlengths[j] = 0\n",
    "            \n",
    "        dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "        get_dt(0, 0)\n",
    "        \n",
    "    for i in range(len(points)):\n",
    "        subtree[i].clear()\n",
    "        parent_count[i] = 0\n",
    "        count[i] = 0\n",
    "        pathlengths[i] = 0\n",
    "        \n",
    "    dfs(0, 0, adj_list, points, subtree, count, parent_count, pathlengths)\n",
    "    for i in range(len(points)):\n",
    "        if parent_count[i] != 1:\n",
    "            print(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "def prim_dijkstra(alpha, points, source_set, nearest_neighbours, T):\n",
    "    N = len(points)\n",
    "    \n",
    "    keys = [float(\"inf\") for i in range(len(points))]\n",
    "    pathlengths = [float(\"inf\") for i in range(len(points))]\n",
    "    parents = [0 for i in range(len(points))]\n",
    "    visited = [False for i in range(len(points))]\n",
    "    \n",
    "    keys[0] = 0\n",
    "    pathlengths[0] = 0\n",
    "    parents[0] = 0\n",
    "    \n",
    "    pq = set()\n",
    "    \n",
    "    for source in source_set:\n",
    "        keys[source] = 0\n",
    "        pathlengths[source] = 0\n",
    "        parents[source] = 0\n",
    "        pq.add(((keys[source], pathlengths[source]), (source, 0)))\n",
    "    \n",
    "    if len(source_set) == 0:\n",
    "        pq.add(((keys[0], pathlengths[0]), (0, 0)))\n",
    "    else:\n",
    "        visited[0] = True\n",
    "        \n",
    "    \n",
    "    while len(pq) > 0:\n",
    "        fr = next(iter(pq))\n",
    "        pq.remove(fr)\n",
    "        \n",
    "        fr_index = fr[1][0]\n",
    "        fr_pathlength = fr[0][1]\n",
    "        \n",
    "        visited[fr_index] = True\n",
    "        \n",
    "        for neighbour_index in nearest_neighbours[fr_index]:\n",
    "            distance = manhattan_distance(\n",
    "                points[fr_index][0][0], points[fr_index][0][1],\n",
    "                points[neighbour_index][0][0], points[neighbour_index][0][1]\n",
    "            )\n",
    "            pathlength = distance + fr_pathlength\n",
    "            weight = alpha * fr_pathlength + distance\n",
    "            \n",
    "            if not visited[neighbour_index] and weight <= keys[fr_pathlength]:\n",
    "                pq.discard((\n",
    "                    (keys[neighbour_index], pathlengths[neighbour_index]),\n",
    "                    (neighbour_index, parents[neighbour_index])\n",
    "                ))\n",
    "                keys[neighbour_index] = weight\n",
    "                pathlengths[neighbour_index] = pathlength\n",
    "                parents[neighbour_index] = fr_index\n",
    "                pq.add((\n",
    "                    (keys[neighbour_index], pathlengths[neighbour_index]),\n",
    "                    (neighbour_index, parents[neighbour_index])\n",
    "                ))\n",
    "                \n",
    "    adj_list = [set() for i in range(N)]\n",
    "    for i in range(N):\n",
    "        adj_list[parents[i]].add(i)\n",
    "        \n",
    "    if T:\n",
    "        steinerize(points, adj_list, parents)\n",
    "        das(source_set, adj_list, parents, N, points)\n",
    "        \n",
    "    return adj_list, parents\n",
    "    \n",
    "\n",
    "def solve(N, source_set, input_df):\n",
    "    # Store the x and y coordinates\n",
    "    X = input_df[[f\"x{i}\" for i in range(N)]].values[0].tolist()\n",
    "    Y = input_df[[f\"y{i}\" for i in range(N)]].values[0].tolist()\n",
    "    \n",
    "    points = [((X[i], Y[i]), i) for i in range(N)]\n",
    "    \n",
    "    nearest_neighbours = get_nearest_neighbours(points)\n",
    "    \n",
    "    alpha = 0.4\n",
    "    \n",
    "    adj_list, parents = prim_dijkstra(alpha, points, source_set, nearest_neighbours, True)\n",
    "    wl = calc_wl(adj_list, points)\n",
    "    skew = calc_skew(adj_list, points, N)\n",
    "    \n",
    "    return wl, skew\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11970, 1907)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(45, [38, 39], inputDf[inputDf[\"netIdx\"] == 299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def genetic_algorithm(N, objectiveN, inputDf):\n",
    "    # Settings\n",
    "    generations = 100\n",
    "    population_size = 20\n",
    "    crossover_rate = 0.7\n",
    "    mutation_rate = 0.05\n",
    "    tournament_size = 5\n",
    "    \n",
    "    fitness_store = {}\n",
    "    \n",
    "    def fitness(chromosome):\n",
    "        # Compute the fitness (score) of each chromosome as the skew value in the constructed PD tree\n",
    "        if tuple(chromosome) in fitness_store:\n",
    "            return fitness_store[tuple(chromosome)]\n",
    "        \n",
    "        wl, skew = solve(N, chromosome, inputDf)\n",
    "        fitness_store[tuple(chromosome)] = -skew\n",
    "        return -skew\n",
    "    \n",
    "    \n",
    "    def tournament_selection(population):\n",
    "        # Select the top parent from a randomised sample\n",
    "        return max(random.sample(population, tournament_size), key=fitness)\n",
    "    \n",
    "    \n",
    "    def crossover(parent1, parent2):\n",
    "        gene_length = len(parent1)\n",
    "        \n",
    "        if gene_length <= 1 or random.random() < crossover_rate:\n",
    "            return parent1, parent2\n",
    "        \n",
    "        # Create a child chromosome by combining genes from two parent chromosomes\n",
    "        # while preserving a middle section of genes from the first parent. This is required\n",
    "        # instead of the standard crossover operation due to possibility of creating invalid\n",
    "        # genes with duplicate values.\n",
    "        # https://github.com/giacomelli/GeneticSharp/blob/master/src/GeneticSharp.Domain/Crossovers/OrderedCrossover.cs\n",
    "        \n",
    "        middle_section_begin, middle_section_end = sorted(random.sample(range(gene_length), 2))\n",
    "        \n",
    "        # Create the first child\n",
    "        child1 = []\n",
    "        # This is O(1) since the gene length is at most 3.\n",
    "        parent1_middle_genes = parent1[middle_section_begin:middle_section_end + 1]\n",
    "        parent2_remaining_genes = iter([gene for gene in parent2 if gene not in parent1_middle_genes])\n",
    "        \n",
    "        for i in range(gene_length):\n",
    "            if middle_section_begin <= i <= middle_section_end:\n",
    "                child1.append(parent1[i])\n",
    "            else:\n",
    "                child1.append(next(parent2_remaining_genes))\n",
    "        \n",
    "        \n",
    "        # Create the second child\n",
    "        child2 = []\n",
    "        parent2_middle_genes = parent2[middle_section_begin:middle_section_end + 1]\n",
    "        parent1_remaining_genes = iter([gene for gene in parent1 if gene not in parent2_middle_genes])\n",
    "        \n",
    "        for i in range(gene_length):\n",
    "            if middle_section_begin <= i <= middle_section_end:\n",
    "                child2.append(parent2[i])\n",
    "            else:\n",
    "                child2.append(next(parent1_remaining_genes))\n",
    "\n",
    "        return child1, child2\n",
    "    \n",
    "    \n",
    "    def mutate(chromosome):\n",
    "        if random.random() < mutation_rate:\n",
    "            return chromosome\n",
    "        \n",
    "        mutation_index = random.randint(0, len(chromosome) - 1)\n",
    "        while True:\n",
    "            new_source = random.choice(range(1, N))\n",
    "            if new_source in chromosome:\n",
    "                # Note that the length of chromosome is again at most 3.\n",
    "                continue\n",
    "                \n",
    "            chromosome[mutation_index] = new_source\n",
    "            break\n",
    "            \n",
    "        return chromosome\n",
    "        \n",
    "    \n",
    "    population = [sorted(random.sample(range(1, N), objectiveN)) for i in range(population_size)]\n",
    "    best_chromosomes = []\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        # Populate the next generation\n",
    "        selected_parents = [tournament_selection(population) for _ in range(population_size)]\n",
    "        next_generation = []\n",
    "        \n",
    "        for i in range(0, population_size, 2):\n",
    "            parent1, parent2 = selected_parents[i], selected_parents[i + 1]\n",
    "            for child in crossover(parent1, parent2):\n",
    "                next_generation.append(sorted(mutate(child)))\n",
    "                \n",
    "        population = next_generation\n",
    "        best_chromosomes.append(max(population, key=fitness))\n",
    "        \n",
    "    return max(best_chromosomes, key=fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for n = 10 , MSE(mean squared error) of three objectives = [0.0790102931718665, 0.1797688426421699, 0.33751842744200306]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-11b9c1c6248c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0misFailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mresultIdxList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectiveN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetInputDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-11b9c1c6248c>\u001b[0m in \u001b[0;36mInference\u001b[0;34m(N, objectiveN, inputDf)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# please return index between 1 and N-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectiveN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9320801dbd58>\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(N, objectiveN, inputDf)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mbest_chromosomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_chromosomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9320801dbd58>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(chromosome)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfitness_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfitness_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(N, source_set, input_df)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprim_dijkstra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnearest_neighbours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0mwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_wl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mskew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_skew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mprim_dijkstra\u001b[0;34m(alpha, points, source_set, nearest_neighbours, T)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msteinerize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mdas\u001b[0;34m(source_set, adj_list, parents, N, points)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dc88db23da98>\u001b[0m in \u001b[0;36mget_dt\u001b[0;34m(at, parent)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         DT[at] = pathlengths[at] - manhattan_distance(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import signal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# contestants are only allowed to modify the following function!\n",
    "# input: a) number of coordinates(N: 10, 15, 20, ... 50),\n",
    "#        b) objective mode (objectiveN: 1,2,3)\n",
    "#        c) input coordinates dataframe (inputDf),\n",
    "# output: the list that has the index of sources\n",
    "\n",
    "######## YOU CAN ONLY MODIFY FROM HERE UNTIL THE NEXT ##.. COMMENTS ###########\n",
    "\n",
    "# Note that you cannot use data_obj_stt_{n}.csv.gz as an input of this function\n",
    "def Inference(N, objectiveN, inputDf):\n",
    "    # simple example of returning three sources\n",
    "\n",
    "    # return example:\n",
    "    # zero sources: return []\n",
    "    # one source: return [1]\n",
    "    #             return [2] ...\n",
    "    # two sources: return [1,2]\n",
    "    #              return [1,3] ...\n",
    "    # three sources: return [1,2,3]\n",
    "    #                return [1,2,4] ...\n",
    "\n",
    "    # Note that the root of the input net (always index 0) cannot be a source\n",
    "    # please return index between 1 and N-1\n",
    "    \n",
    "    result = genetic_algorithm(N, objectiveN, inputDf)\n",
    "    return result\n",
    "\n",
    "\n",
    "######### DO NOT MODIFY FROM HERE ONWARD ############\n",
    "\n",
    "# runtime exceed handler\n",
    "def Handler(signum, frame):\n",
    "    print(\"Exceed 10s Runtime Limit\")\n",
    "    raise Exception(\"Runtime Limit Exceeds\")\n",
    "\n",
    "\n",
    "# input: list of sources\n",
    "# output: corresponding index from sourceDataFrame\n",
    "def GetResultIdx(resultIdxList, sourceDf):\n",
    "    N = len(sourceDf.columns) - 1\n",
    "    # error handling\n",
    "    if len(resultIdxList) >= 4:\n",
    "        print(\"Error: found #sources >=4. #sources are limited <= 3\")\n",
    "        exit(1)\n",
    "    if len(resultIdxList) != 0 and (min(resultIdxList) <= 0 or max(resultIdxList) >= N):\n",
    "        print(\"Error: index exceeded expected ranges. Please double-check your indices.\")\n",
    "        print(\"Expected index range is 1~N-1, but range is min=\", min(resultIdxList), \"max=\", max(resultIdxList),)\n",
    "        exit(1)\n",
    "\n",
    "    sourceArr = [0] * N\n",
    "    for val in resultIdxList:\n",
    "        sourceArr[val] = 1\n",
    "\n",
    "    mask = True\n",
    "    for i, val in enumerate(sourceArr):\n",
    "        mask = mask & (sourceDf[\"%d\" % (i)] == val)\n",
    "\n",
    "    # return sourceIdx value from the source dataframe\n",
    "    return sourceDf.loc[mask][\"sourceIdx\"].values[0]\n",
    "\n",
    "\n",
    "# signal setup for maximum runtime limit\n",
    "signal.signal(signal.SIGALRM, Handler)\n",
    "\n",
    "listK = [1, 1]#1, 1, 2, 2, 2]\n",
    "MSEs = []\n",
    "\n",
    "# for various N\n",
    "for n in [10, 15]:#, 25, 30, 40, 45, 50]:\n",
    "    dataObjDf = pd.read_csv(\n",
    "        \"testcases/data_obj_stt_%d.csv.gz\" % (n), compression=\"gzip\"\n",
    "    )\n",
    "    inputDf = pd.read_csv(\"testcases/input_stt_%d.csv.gz\" % (n), compression=\"gzip\")\n",
    "    sourceDf = pd.read_csv(\"testcases/sources_stt_%d.csv.gz\" % (n), compression=\"gzip\")\n",
    "\n",
    "    # save predicted result\n",
    "    # first index: N\n",
    "    # second index: netIdx\n",
    "    predictArr = [[], [], []]\n",
    "\n",
    "    # there will be hidden testcases (200 more nets)\n",
    "    for netIdx in range(0, 300):\n",
    "        netInputDf = inputDf.loc[inputDf[\"netIdx\"] == netIdx]\n",
    "        netDataObjDf = dataObjDf.loc[dataObjDf[\"netIdx\"] == netIdx]\n",
    "\n",
    "        # for each objective (1,2,3)\n",
    "        for objectiveN in range(1, 4):\n",
    "            # for runtime limit - 10 seconds\n",
    "            signal.alarm(10)\n",
    "\n",
    "            # call the Inference function\n",
    "            isFailed = False\n",
    "            try:\n",
    "                resultIdxList = Inference(n, objectiveN, netInputDf)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Warning: Runtime Limit Exceeded. Penalty will be applied\")\n",
    "                isFailed = True\n",
    "\n",
    "            if isFailed == False:\n",
    "                # retrieve sourceIdx using sourceDataFrame\n",
    "                resultIdx = GetResultIdx(resultIdxList, sourceDf)\n",
    "\n",
    "                predictedObj = netDataObjDf.loc[netDataObjDf[\"sourceIdx\"] == resultIdx][\n",
    "                    \"obj%d\" % (objectiveN)\n",
    "                ].values[0]\n",
    "                predictArr[objectiveN - 1].append(predictedObj)\n",
    "            else:\n",
    "                # append \"-1\" flag variable - runtime exceeded\n",
    "                predictArr[objectiveN - 1].append(-1)\n",
    "\n",
    "        # extract the best cost value\n",
    "        bestCostValue = [netDataObjDf[\"obj%d\" % (i)].min() for i in range(1, 4)]\n",
    "\n",
    "        # take the \"ratio\" instead of raw value\n",
    "        # predictedValue /= bestCostValue\n",
    "        for i, val in enumerate(bestCostValue):\n",
    "            # normal predicted case\n",
    "            if predictArr[i][-1] != -1:\n",
    "                predictArr[i][-1] /= val\n",
    "            # runtime exceeded case\n",
    "            else:\n",
    "                predictArr[i][-1] = 1.5\n",
    "\n",
    "    # best cost is normalized as \"1\"\n",
    "    bestCostArr = [[1] * len(predictArr[0]) for _ in range(3)]\n",
    "\n",
    "    MSE = [mean_squared_error(bestCostArr[i], predictArr[i]) for i in range(3)]\n",
    "    print(\"for n =\", n, \", MSE(mean squared error) of three objectives =\", MSE)\n",
    "    MSEs.append(MSE)\n",
    "\n",
    "evalMetric = 0\n",
    "for k, MSE in zip(listK, MSEs):\n",
    "    evalMetric += k * sum(MSE)\n",
    "\n",
    "print(\"EvalMetric: \", evalMetric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
